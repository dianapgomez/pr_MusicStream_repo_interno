{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cnx = mysql.connector.connect(user='root', password='AlumnaAdalab',\n",
    "                              host='127.0.0.1',\n",
    "                              database ='StreamMusic2',\n",
    "                            auth_plugin ='mysql_native_password')\n",
    "    \n",
    "\n",
    "    mycursor = cnx.cursor()\n",
    "    \n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(err)\n",
    "    print(\"Error Code:\", err.errno)\n",
    "    print(\"SQLSTATE\", err.sqlstate)\n",
    "    print(\"Message\", err.msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_create_schema = \"\"\"CREATE SCHEMA StreamMusic2\"\"\"\n",
    "mycursor.execute(query_create_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute('USE StreamMusic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_creation = {\n",
    "                        'API_Eurovision' : \"\"\"CREATE TABLE api_eurovision (\n",
    "                                            ID SMALLINT NOT NULL AUTO_INCREMENT,\n",
    "                                            EurovisionYear YEAR NOT NULL,\n",
    "                                            Ranking INT NOT NULL,\n",
    "                                            Artist VARCHAR(45) NOT NULL,                              \n",
    "                                            Track VARCHAR(70) NOT NULL,\n",
    "                                            Country VARCHAR(3) NOT NULL,\n",
    "                                            PRIMARY KEY (ID))\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table: API_Eurovision\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for k, v in dict_table_creation.items():\n",
    "    print(f'Creating table: {k}')\n",
    "    mycursor.execute(v)\n",
    "\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSERT EUROVISION API DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_api_eu(year, tuples):\n",
    "    query_table = \"\"\"INSERT INTO API_EUROVISION (EurovisionYear, Ranking, Artist, Track, Country)\n",
    "                    VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    tuples_year = [(year, *t) for t in tuples]\n",
    "\n",
    "    mycursor = cnx.cursor()\n",
    "    mycursor.executemany(query_table,  tuples_year)\n",
    "    print(mycursor.rowcount,'values entered')\n",
    "    cnx.commit()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_eurovision2019 = pd.read_csv(\"../files/Eurovision/2019/euro_ranking2019.csv\", index_col=0)\n",
    "api_eurovision2019_tuples = list(df_api_eurovision2019.itertuples(index=False, name=None))\n",
    "year19 = 2019\n",
    "insert_api_eu(year19, api_eurovision2019_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_eurovision2021 = pd.read_csv(\"../files/Eurovision/2021/euro_ranking2021.csv\", index_col=0)\n",
    "api_eurovision2021_tuples = list(df_api_eurovision2021.itertuples(index=False, name=None))\n",
    "year_21 = 2021\n",
    "insert_api_eu(year_21, api_eurovision2021_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_eurovision2022 = pd.read_csv(\"../files/Eurovision/2022/euro_ranking2022.csv\", index_col=0)\n",
    "api_eurovision2022_tuples = list(df_api_eurovision2022.itertuples(index=False, name=None))\n",
    "año_22 = 2022\n",
    "\n",
    "insert_api_eu(año_22, api_eurovision2022_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_eurovision2023 = pd.read_csv(\"../files/Eurovision/2023/euro_ranking2023.csv\", index_col=0)\n",
    "api_eurovision2023_tuples = list(df_api_eurovision2023.itertuples(index=False, name=None))\n",
    "year_23 = 2023\n",
    "\n",
    "insert_api_eu(year_23, api_eurovision2023_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_eurovision2024 = pd.read_csv(\"../files/Eurovision/2024/euro_ranking2024.csv\", index_col=0)\n",
    "api_eurovision2024_tuples = list(df_api_eurovision2024.itertuples(index=False, name=None))\n",
    "year_24 = 2024\n",
    "\n",
    "insert_api_eu(year_24, api_eurovision2024_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE API_SPOTIFY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_creation = {'API_Spotify' :     \"\"\"CREATE TABLE api_spotify_playlist (\n",
    "                                            ID INT NOT NULL AUTO_INCREMENT,\n",
    "                                            Artist VARCHAR(45) NOT NULL,\n",
    "                                            Track VARCHAR(70) NOT NULL,\n",
    "                                            Popularity INT NOT NULL,\n",
    "                                            EurovisionYear YEAR NOT NULL,\n",
    "                                            Duration INT NOT NULL,\n",
    "                                            PRIMARY KEY (ID))\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table: API_Spotify\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for k, v in dict_table_creation.items():\n",
    "    print(f'Creating table: {k}')\n",
    "    mycursor.execute(v)\n",
    "\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSERT SPOTIFY API DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_api_spotify(year, tuples):\n",
    "    query_table = \"\"\"INSERT INTO api_spotify_playlist (Artist, Track, Popularity, EurovisionYear, Duration)\n",
    "                    VALUES (%s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    tuples_year = [(t[:3] + (year,) + t[3:]) for t in tuples]\n",
    "\n",
    "    mycursor = cnx.cursor()\n",
    "    mycursor.executemany(query_table,  tuples_year)\n",
    "    print(mycursor.rowcount,'values entered')\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_spotify2019 = pd.read_csv(\"../files/Spotify_sql/eurovision2019.csv\", index_col=0)\n",
    "api_spotify2019_tuples = list(df_api_spotify2019.itertuples(index=False, name=None))\n",
    "year19 = 2019\n",
    "insert_api_spotify(year19, api_spotify2019_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_spotify2021 = pd.read_csv(\"../files/Spotify_sql/eurovision2021.csv\", index_col=0)\n",
    "api_spotify2021_tuples = list(df_api_spotify2021.itertuples(index=False, name=None))\n",
    "year21 = 2021\n",
    "insert_api_spotify(year21, api_spotify2021_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_spotify2022 = pd.read_csv(\"../files/Spotify_sql/eurovision2022.csv\", index_col=0)\n",
    "api_spotify2022_tuples = list(df_api_spotify2022.itertuples(index=False, name=None))\n",
    "year22 = 2022\n",
    "insert_api_spotify(year22, api_spotify2022_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_spotify2023 = pd.read_csv(\"../files/Spotify_sql/eurovision2023.csv\", index_col=0)\n",
    "api_spotify2023_tuples = list(df_api_spotify2023.itertuples(index=False, name=None))\n",
    "year23 = 2023\n",
    "insert_api_spotify(year23, api_spotify2023_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 values entered\n"
     ]
    }
   ],
   "source": [
    "df_api_spotify2024 = pd.read_csv(\"../files/Spotify_sql/eurovision2024.csv\", index_col=0)\n",
    "api_spotify2024_tuples = list(df_api_spotify2024.itertuples(index=False, name=None))\n",
    "year24 = 2024\n",
    "insert_api_spotify(year24, api_spotify2024_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSERT LAST FM API DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_table_creation = {'API_LastFM_Info_Artists' : \"\"\"CREATE TABLE api_lastfm_info_artists (\n",
    "                                                    ID INT NOT NULL AUTO_INCREMENT,\n",
    "                                                    Artist VARCHAR(45) NOT NULL,\n",
    "                                                    Listeners INT,\n",
    "                                                    Playcount INT,\n",
    "                                                    Genre1 VARCHAR(45) NULL,\n",
    "                                                    Genre2 VARCHAR(45) NULL,\n",
    "                                                    Genre3 VARCHAR(45) NULL,\n",
    "                                                    Similar_Artists1 VARCHAR(45) NULL,\n",
    "                                                    Similar_Artists2 VARCHAR(45) NULL,\n",
    "                                                    Similar_Artists3 VARCHAR(45) NULL,\n",
    "                                                    Bio TEXT, \n",
    "                                                    PRIMARY KEY (ID))\"\"\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table: API_LastFM_Info_Artists\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for k, v in dict_table_creation.items():\n",
    "    print(f'Creating table: {k}')\n",
    "    mycursor.execute(v)\n",
    "\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_api_lastfm(tuples):\n",
    "    query_table = \"\"\"INSERT INTO api_lastfm_info_artists (Artist, Listeners, Playcount, Genre1, Genre2, Genre3, Similar_Artists1,Similar_Artists2, Similar_Artists3, Bio)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "\n",
    "    mycursor = cnx.cursor()\n",
    "    mycursor.executemany(query_table, tuples)\n",
    "    print(mycursor.rowcount,'values entered')\n",
    "    cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 3, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_api_lastfm2019_artists \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../files/LastFm/2019/info_artists_2019.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m api_lastfm2019_tuples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df_api_lastfm2019_artists\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m      3\u001b[0m insert_api_lastfm(api_lastfm2019_tuples)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 3, saw 3\n"
     ]
    }
   ],
   "source": [
    "df_api_lastfm2019_artists = pd.read_csv(\"../files/LastFm/2019/info_artists_2019.csv\", index_col=0, encoding=\"utf-8\")\n",
    "api_lastfm2019_tuples = list(df_api_lastfm2019_artists.itertuples(index=False, name=None))\n",
    "insert_api_lastfm(api_lastfm2019_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api_lastfm2019_artists = pd.read_csv(\"../files/LastFm/2019/top_tracks_2019.csv\",index_col=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
